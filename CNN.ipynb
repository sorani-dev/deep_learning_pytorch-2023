{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# CNN"
      ],
      "metadata": {
        "id": "b4OGlyZIGlU9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import MNIST Images - Deep Learning with PyTorch 14"
      ],
      "metadata": {
        "id": "p52DC1n9Gpl0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "6BToejRRuL0l"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.utils import make_grid\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert MNIST Image Files into a Tensor of 4-Dimensions (# of images, Height, Width, Color Channel)\n",
        "transform = transforms.ToTensor()"
      ],
      "metadata": {
        "id": "yDG3T4NTudNz"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Data\n",
        "train_data = datasets.MNIST(root='/cnn_data', train=True, download=True, transform=transform)"
      ],
      "metadata": {
        "id": "JNrUQJFSwRIx"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test Data\n",
        "test_data = datasets.MNIST(root='/cnn_data', train=False, download=True, transform=transform)"
      ],
      "metadata": {
        "id": "1qH7E6jSw4T3"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "CpM4Rj-lxovy",
        "outputId": "7e79b215-d75c-4d88-b9c3-f15e266b4917"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset MNIST\n",
              "    Number of datapoints: 60000\n",
              "    Root location: /cnn_data\n",
              "    Split: Train\n",
              "    StandardTransform\n",
              "Transform: ToTensor()"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "K-T5izyM8kfC",
        "outputId": "d072bcbd-4d13-4f47-c3c6-b386c7e840ab"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset MNIST\n",
              "    Number of datapoints: 10000\n",
              "    Root location: /cnn_data\n",
              "    Split: Test\n",
              "    StandardTransform\n",
              "Transform: ToTensor()"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "1odcl24FGAqU",
        "outputId": "ac253ad6-baf2-4e7a-c33f-77562a19295b"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "I3ov30OaGAtC",
        "outputId": "67c3255b-044e-4d9f-a6a0-fd80721c55f4"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd ../"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "gGKtmsuPGAv8",
        "outputId": "73c66ef8-69e1-4e63-b5d1-22087ee94823"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls -al"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "EvzzZ6uoGAyh",
        "outputId": "bb489176-9487-4712-efe4-10be81e43587"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 116\n",
            "drwxr-xr-x   1 root root  4096 Oct 17 19:12 \u001b[0m\u001b[01;34m.\u001b[0m/\n",
            "drwxr-xr-x   1 root root  4096 Oct 17 19:12 \u001b[01;34m..\u001b[0m/\n",
            "lrwxrwxrwx   1 root root     7 Jun  5 14:02 \u001b[01;36mbin\u001b[0m -> \u001b[01;34musr/bin\u001b[0m/\n",
            "drwxr-xr-x   2 root root  4096 Apr 18  2022 \u001b[01;34mboot\u001b[0m/\n",
            "drwxr-xr-x   3 root root  4096 Oct 17 19:12 \u001b[01;34mcnn_data\u001b[0m/\n",
            "drwxr-xr-x   1 root root  4096 Oct 16 13:23 \u001b[01;34mcontent\u001b[0m/\n",
            "-rw-r--r--   1 root root  4332 Jun 21 00:40 cuda-keyring_1.0-1_all.deb\n",
            "drwxr-xr-x   1 root root  4096 Oct 16 13:52 \u001b[01;34mdatalab\u001b[0m/\n",
            "drwxr-xr-x   5 root root   360 Oct 17 19:11 \u001b[01;34mdev\u001b[0m/\n",
            "-rwxr-xr-x   1 root root     0 Oct 17 19:11 \u001b[01;32m.dockerenv\u001b[0m*\n",
            "drwxr-xr-x   1 root root  4096 Oct 17 19:11 \u001b[01;34metc\u001b[0m/\n",
            "drwxr-xr-x   2 root root  4096 Apr 18  2022 \u001b[01;34mhome\u001b[0m/\n",
            "lrwxrwxrwx   1 root root     7 Jun  5 14:02 \u001b[01;36mlib\u001b[0m -> \u001b[01;34musr/lib\u001b[0m/\n",
            "lrwxrwxrwx   1 root root     9 Jun  5 14:02 \u001b[01;36mlib32\u001b[0m -> \u001b[01;34musr/lib32\u001b[0m/\n",
            "lrwxrwxrwx   1 root root     9 Jun  5 14:02 \u001b[01;36mlib64\u001b[0m -> \u001b[01;34musr/lib64\u001b[0m/\n",
            "lrwxrwxrwx   1 root root    10 Jun  5 14:02 \u001b[01;36mlibx32\u001b[0m -> \u001b[01;34musr/libx32\u001b[0m/\n",
            "drwxr-xr-x   2 root root  4096 Jun  5 14:02 \u001b[01;34mmedia\u001b[0m/\n",
            "drwxr-xr-x   2 root root  4096 Jun  5 14:02 \u001b[01;34mmnt\u001b[0m/\n",
            "-rw-r--r--   1 root root 17294 Jun 21 00:39 NGC-DL-CONTAINER-LICENSE\n",
            "drwxr-xr-x   1 root root  4096 Oct 16 13:53 \u001b[01;34mopt\u001b[0m/\n",
            "dr-xr-xr-x 175 root root     0 Oct 17 19:11 \u001b[01;34mproc\u001b[0m/\n",
            "drwxr-xr-x  15 root root  4096 Oct 16 13:20 \u001b[01;34mpython-apt\u001b[0m/\n",
            "drwx------   1 root root  4096 Oct 16 13:53 \u001b[01;34mroot\u001b[0m/\n",
            "drwxr-xr-x   1 root root  4096 Oct 16 13:15 \u001b[01;34mrun\u001b[0m/\n",
            "lrwxrwxrwx   1 root root     8 Jun  5 14:02 \u001b[01;36msbin\u001b[0m -> \u001b[01;34musr/sbin\u001b[0m/\n",
            "drwxr-xr-x   2 root root  4096 Jun  5 14:02 \u001b[01;34msrv\u001b[0m/\n",
            "dr-xr-xr-x  13 root root     0 Oct 17 19:11 \u001b[01;34msys\u001b[0m/\n",
            "drwxrwxrwt   1 root root  4096 Oct 17 19:11 \u001b[30;42mtmp\u001b[0m/\n",
            "drwxr-xr-x   1 root root  4096 Oct 16 13:39 \u001b[01;34mtools\u001b[0m/\n",
            "drwxr-xr-x   1 root root  4096 Oct 16 13:53 \u001b[01;34musr\u001b[0m/\n",
            "drwxr-xr-x   1 root root  4096 Oct 16 13:52 \u001b[01;34mvar\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd cnn_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "-UieNm_vGPJD",
        "outputId": "8f5dea42-d539-4bfb-b818-b364809bfbe9"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/cnn_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls -l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "A6vG6xBWGPL2",
        "outputId": "71930c25-87e6-457e-82e7-1434176b161f"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 4\n",
            "drwxr-xr-x 3 root root 4096 Oct 17 19:12 \u001b[0m\u001b[01;34mMNIST\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "GusKlHS7GPOu",
        "outputId": "c96cc111-b91e-4a13-fa57-f5dec3722da1"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls -l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "jawPRjssGX1y",
        "outputId": "f3926106-5499-43bf-d573-81fe54fd593b"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 108\n",
            "lrwxrwxrwx   1 root root     7 Jun  5 14:02 \u001b[0m\u001b[01;36mbin\u001b[0m -> \u001b[01;34musr/bin\u001b[0m/\n",
            "drwxr-xr-x   2 root root  4096 Apr 18  2022 \u001b[01;34mboot\u001b[0m/\n",
            "drwxr-xr-x   3 root root  4096 Oct 17 19:12 \u001b[01;34mcnn_data\u001b[0m/\n",
            "drwxr-xr-x   1 root root  4096 Oct 16 13:23 \u001b[01;34mcontent\u001b[0m/\n",
            "-rw-r--r--   1 root root  4332 Jun 21 00:40 cuda-keyring_1.0-1_all.deb\n",
            "drwxr-xr-x   1 root root  4096 Oct 16 13:52 \u001b[01;34mdatalab\u001b[0m/\n",
            "drwxr-xr-x   5 root root   360 Oct 17 19:11 \u001b[01;34mdev\u001b[0m/\n",
            "drwxr-xr-x   1 root root  4096 Oct 17 19:11 \u001b[01;34metc\u001b[0m/\n",
            "drwxr-xr-x   2 root root  4096 Apr 18  2022 \u001b[01;34mhome\u001b[0m/\n",
            "lrwxrwxrwx   1 root root     7 Jun  5 14:02 \u001b[01;36mlib\u001b[0m -> \u001b[01;34musr/lib\u001b[0m/\n",
            "lrwxrwxrwx   1 root root     9 Jun  5 14:02 \u001b[01;36mlib32\u001b[0m -> \u001b[01;34musr/lib32\u001b[0m/\n",
            "lrwxrwxrwx   1 root root     9 Jun  5 14:02 \u001b[01;36mlib64\u001b[0m -> \u001b[01;34musr/lib64\u001b[0m/\n",
            "lrwxrwxrwx   1 root root    10 Jun  5 14:02 \u001b[01;36mlibx32\u001b[0m -> \u001b[01;34musr/libx32\u001b[0m/\n",
            "drwxr-xr-x   2 root root  4096 Jun  5 14:02 \u001b[01;34mmedia\u001b[0m/\n",
            "drwxr-xr-x   2 root root  4096 Jun  5 14:02 \u001b[01;34mmnt\u001b[0m/\n",
            "-rw-r--r--   1 root root 17294 Jun 21 00:39 NGC-DL-CONTAINER-LICENSE\n",
            "drwxr-xr-x   1 root root  4096 Oct 16 13:53 \u001b[01;34mopt\u001b[0m/\n",
            "dr-xr-xr-x 175 root root     0 Oct 17 19:11 \u001b[01;34mproc\u001b[0m/\n",
            "drwxr-xr-x  15 root root  4096 Oct 16 13:20 \u001b[01;34mpython-apt\u001b[0m/\n",
            "drwx------   1 root root  4096 Oct 16 13:53 \u001b[01;34mroot\u001b[0m/\n",
            "drwxr-xr-x   1 root root  4096 Oct 16 13:15 \u001b[01;34mrun\u001b[0m/\n",
            "lrwxrwxrwx   1 root root     8 Jun  5 14:02 \u001b[01;36msbin\u001b[0m -> \u001b[01;34musr/sbin\u001b[0m/\n",
            "drwxr-xr-x   2 root root  4096 Jun  5 14:02 \u001b[01;34msrv\u001b[0m/\n",
            "dr-xr-xr-x  13 root root     0 Oct 17 19:11 \u001b[01;34msys\u001b[0m/\n",
            "drwxrwxrwt   1 root root  4096 Oct 17 19:11 \u001b[30;42mtmp\u001b[0m/\n",
            "drwxr-xr-x   1 root root  4096 Oct 16 13:39 \u001b[01;34mtools\u001b[0m/\n",
            "drwxr-xr-x   1 root root  4096 Oct 16 13:53 \u001b[01;34musr\u001b[0m/\n",
            "drwxr-xr-x   1 root root  4096 Oct 16 13:52 \u001b[01;34mvar\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd content/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "qKIa2Ib8GVLz",
        "outputId": "4a2a638b-d02e-4ebf-8b31-22fc5ce2411c"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls -al"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "oEwOZe-2GVOn",
        "outputId": "26ebed2e-09d6-405e-bbd9-1cb7854ded7e"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 16\n",
            "drwxr-xr-x 1 root root 4096 Oct 16 13:23 \u001b[0m\u001b[01;34m.\u001b[0m/\n",
            "drwxr-xr-x 1 root root 4096 Oct 17 19:12 \u001b[01;34m..\u001b[0m/\n",
            "drwxr-xr-x 4 root root 4096 Oct 16 13:23 \u001b[01;34m.config\u001b[0m/\n",
            "drwxr-xr-x 1 root root 4096 Oct 16 13:23 \u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convolutional and Pooling Layers - Deep Learning with PyTorch 15\n"
      ],
      "metadata": {
        "id": "eP3wUnIvGg6y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "2RtJVuZRGeQq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a small batch size for images...  let's say 10\n",
        "train_loader = DataLoader(train_data, batch_size=10, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=10, shuffle=False)"
      ],
      "metadata": {
        "id": "wo-rFFRtDRhr"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the CNN Model\n",
        "# Decribe the convolutional layer and what it's doing (2 convolutional layers)\n",
        "# This is an example\n",
        "conv1 = nn.Conv2d(1, 6, 3, 1)\n",
        "conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=3, stride=1)\n"
      ],
      "metadata": {
        "id": "Rn0RJXAID7id"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Grab 1 MNIST record/image\n",
        "for i, (X_train, y_train) in enumerate(train_data):\n",
        "  break"
      ],
      "metadata": {
        "id": "gNMCIZGZE3Km"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "qw83YVr2HN-s",
        "outputId": "1700eb48-e3f9-4849-a63c-e3cc9715baa3"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0706, 0.0706, 0.0706,\n",
              "          0.4941, 0.5333, 0.6863, 0.1020, 0.6510, 1.0000, 0.9686, 0.4980,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.1176, 0.1412, 0.3686, 0.6039, 0.6667, 0.9922, 0.9922, 0.9922,\n",
              "          0.9922, 0.9922, 0.8824, 0.6745, 0.9922, 0.9490, 0.7647, 0.2510,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1922,\n",
              "          0.9333, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
              "          0.9922, 0.9843, 0.3647, 0.3216, 0.3216, 0.2196, 0.1529, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706,\n",
              "          0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765, 0.7137,\n",
              "          0.9686, 0.9451, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.3137, 0.6118, 0.4196, 0.9922, 0.9922, 0.8039, 0.0431, 0.0000,\n",
              "          0.1686, 0.6039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0549, 0.0039, 0.6039, 0.9922, 0.3529, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.5451, 0.9922, 0.7451, 0.0078, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0431, 0.7451, 0.9922, 0.2745, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.1373, 0.9451, 0.8824, 0.6275,\n",
              "          0.4235, 0.0039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3176, 0.9412, 0.9922,\n",
              "          0.9922, 0.4667, 0.0980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1765, 0.7294,\n",
              "          0.9922, 0.9922, 0.5882, 0.1059, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0627,\n",
              "          0.3647, 0.9882, 0.9922, 0.7333, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.9765, 0.9922, 0.9765, 0.2510, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1804, 0.5098,\n",
              "          0.7176, 0.9922, 0.9922, 0.8118, 0.0078, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.1529, 0.5804, 0.8980, 0.9922,\n",
              "          0.9922, 0.9922, 0.9804, 0.7137, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0941, 0.4471, 0.8667, 0.9922, 0.9922, 0.9922,\n",
              "          0.9922, 0.7882, 0.3059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0902, 0.2588, 0.8353, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765,\n",
              "          0.3176, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.6706,\n",
              "          0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.7647, 0.3137, 0.0353,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.2157, 0.6745, 0.8863, 0.9922,\n",
              "          0.9922, 0.9922, 0.9922, 0.9569, 0.5216, 0.0431, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.5333, 0.9922, 0.9922, 0.9922,\n",
              "          0.8314, 0.5294, 0.5176, 0.0627, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000]]])"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "u53ZHUzgFYu_",
        "outputId": "53da4b73-6dd3-4f8c-aa33-8037498753ac"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = X_train.view(1,1, 28, 28)"
      ],
      "metadata": {
        "id": "7IwlcOA1FbVI"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform the first convolution\n",
        "x = F.relu(conv1(x)) # Rectified Linear Unit for the activation function"
      ],
      "metadata": {
        "id": "KCa9Au_IFwtY"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "gWOjl8QEHIg8",
        "outputId": "b3547547-0686-4f97-acef-ef4421fc6bbf"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[0.1709, 0.1709, 0.1709,  ..., 0.1709, 0.1709, 0.1709],\n",
              "          [0.1709, 0.1709, 0.1709,  ..., 0.1709, 0.1709, 0.1709],\n",
              "          [0.1709, 0.1709, 0.1709,  ..., 0.1709, 0.1709, 0.1709],\n",
              "          ...,\n",
              "          [0.1709, 0.1709, 0.1158,  ..., 0.1709, 0.1709, 0.1709],\n",
              "          [0.1709, 0.1709, 0.1537,  ..., 0.1709, 0.1709, 0.1709],\n",
              "          [0.1709, 0.1709, 0.1709,  ..., 0.1709, 0.1709, 0.1709]],\n",
              "\n",
              "         [[0.0006, 0.0006, 0.0006,  ..., 0.0006, 0.0006, 0.0006],\n",
              "          [0.0006, 0.0006, 0.0006,  ..., 0.0006, 0.0006, 0.0006],\n",
              "          [0.0006, 0.0006, 0.0006,  ..., 0.0006, 0.0006, 0.0006],\n",
              "          ...,\n",
              "          [0.0006, 0.0006, 0.1298,  ..., 0.0006, 0.0006, 0.0006],\n",
              "          [0.0006, 0.0006, 0.0454,  ..., 0.0006, 0.0006, 0.0006],\n",
              "          [0.0006, 0.0006, 0.0006,  ..., 0.0006, 0.0006, 0.0006]],\n",
              "\n",
              "         [[0.1699, 0.1699, 0.1699,  ..., 0.1699, 0.1699, 0.1699],\n",
              "          [0.1699, 0.1699, 0.1699,  ..., 0.1699, 0.1699, 0.1699],\n",
              "          [0.1699, 0.1699, 0.1699,  ..., 0.1699, 0.1699, 0.1699],\n",
              "          ...,\n",
              "          [0.1699, 0.1699, 0.3766,  ..., 0.1699, 0.1699, 0.1699],\n",
              "          [0.1699, 0.1699, 0.3260,  ..., 0.1699, 0.1699, 0.1699],\n",
              "          [0.1699, 0.1699, 0.1699,  ..., 0.1699, 0.1699, 0.1699]],\n",
              "\n",
              "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
              "          ...,\n",
              "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
              "\n",
              "         [[0.0591, 0.0591, 0.0591,  ..., 0.0591, 0.0591, 0.0591],\n",
              "          [0.0591, 0.0591, 0.0591,  ..., 0.0591, 0.0591, 0.0591],\n",
              "          [0.0591, 0.0591, 0.0591,  ..., 0.0591, 0.0591, 0.0591],\n",
              "          ...,\n",
              "          [0.0591, 0.0591, 0.0000,  ..., 0.0591, 0.0591, 0.0591],\n",
              "          [0.0591, 0.0591, 0.1010,  ..., 0.0591, 0.0591, 0.0591],\n",
              "          [0.0591, 0.0591, 0.0591,  ..., 0.0591, 0.0591, 0.0591]],\n",
              "\n",
              "         [[0.3034, 0.3034, 0.3034,  ..., 0.3034, 0.3034, 0.3034],\n",
              "          [0.3034, 0.3034, 0.3034,  ..., 0.3034, 0.3034, 0.3034],\n",
              "          [0.3034, 0.3034, 0.3034,  ..., 0.3034, 0.3034, 0.3034],\n",
              "          ...,\n",
              "          [0.3034, 0.3034, 0.4017,  ..., 0.3034, 0.3034, 0.3034],\n",
              "          [0.3034, 0.3034, 0.4095,  ..., 0.3034, 0.3034, 0.3034],\n",
              "          [0.3034, 0.3034, 0.3034,  ..., 0.3034, 0.3034, 0.3034]]]],\n",
              "       grad_fn=<ReluBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1 is the single image, 6 is the filters asked for, 26x26\n",
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "nomKOYYWHJAq",
        "outputId": "6e930a0b-5a7d-4307-8da7-310b18588af2"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 6, 26, 26])"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pass through the pooling layer\n",
        "x = F.max_pool2d(x, 2, 2) # Kernel of 2 and stride of 2"
      ],
      "metadata": {
        "id": "dBKj0-csHX-L"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape # 26 / 2 = 13"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "B0ihX7lnIO8G",
        "outputId": "7bafaeab-9db9-4fd6-d56a-e71107b5db18"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 6, 13, 13])"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Do the second convolutional layer\n",
        "x = F.relu(conv2(x))"
      ],
      "metadata": {
        "id": "L3f7UHxMIZ7s"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape # Again, no padding was specified so 2 pixels were lost around the outside of the image"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "aMtMMPneI6BY",
        "outputId": "d02f5f8d-5218-4c7a-ed13-1476cedfd93c"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 16, 11, 11])"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pooling layer\n",
        "x = F.max_pool2d(x, 2, 2)"
      ],
      "metadata": {
        "id": "cZoOMCuUI7Uf"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape # 11 / 2 = 5.5 but it is rounded down because no data can invented to round up"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "bsrhQBwUJR0q",
        "outputId": "c5d7f4d4-c887-43d2-8166-63cb5884e49d"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 16, 5, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(((28-2) / 2) -2) / 2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "A2Q12s36JTsE",
        "outputId": "bbd658d6-c4f7-49c0-8f8f-47469eb77424"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5.5"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convolutional Neural Network Model - Deep Learning with PyTorch 16\n"
      ],
      "metadata": {
        "id": "SnS7ESb9KfjQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Class\n",
        "class ConvolutionalNetwork(nn.Module):\n",
        "  def __init__(self) -> None:\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(1, 6, 3, 1)\n",
        "    self.conv2 = nn.Conv2d(6, 16, 3, 1)\n",
        "\n",
        "    # Fully Connected Layers\n",
        "    self.fc1 = nn.Linear(5*5*16, 120)\n",
        "    self.fc2 = nn.Linear(120, 84)\n",
        "    self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "  def forward(self, X):\n",
        "    X = F.relu(self.conv1(X))\n",
        "    X = F.max_pool2d(X, 2, 2) # 2x2 kernel and stride = 2\n",
        "    # Second pass\n",
        "    X = F.relu(self.conv2(X))\n",
        "    X = F.max_pool2d(X, 2, 2) # 2x2 kernel and stride = 2\n",
        "\n",
        "    # Re-View the data to flatten it out\n",
        "    X = X.view(-1, 16*5*5) # Negative one so the batch size can be varied\n",
        "\n",
        "    # Fully Connected Layers\n",
        "    X = F.relu(self.fc1(X))\n",
        "    X = F.relu(self.fc2(X))\n",
        "    X = self.fc3(X)\n",
        "\n",
        "    return F.log_softmax(X, dim=1)\n",
        "\n"
      ],
      "metadata": {
        "id": "rNfrfdybKhsX"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an Instance of the Model\n",
        "torch.manual_seed(41)\n",
        "model = ConvolutionalNetwork()\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Niysr8D9NJQQ",
        "outputId": "b8cec26d-8f0f-4637-decf-48e21cd58548"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ConvolutionalNetwork(\n",
              "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
              "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
              "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss Function Optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) # The smaller the learning rate, the longer it's going to take to train"
      ],
      "metadata": {
        "id": "JxAGUwiENgox"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train and Test CNN Model - Deep Learning with PyTorch 17"
      ],
      "metadata": {
        "id": "fXZl6iqUOz7Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "# Create Variables to track things\n",
        "epochs = 5\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "train_correct = []\n",
        "test_correct = []\n",
        "\n",
        "\n",
        "# For Loop offor Epochs\n",
        "for i in range(epochs):\n",
        "  training_correct = 0\n",
        "  testing_correct = 0\n",
        "\n",
        "  # Train\n",
        "  for b, (X_train, y_train) in enumerate(train_loader):\n",
        "    b += 1 # Start the batches at 1\n",
        "\n",
        "    y_pred = model(X_train) # Get the predicted values from the training set (data is 2d, not flattened.)\n",
        "    loss = criterion(y_pred, y_train) # How off are we? Compare the predictions to the correct answers in y_train\n",
        "\n",
        "    predicted = torch.max(y_pred.data, 1)[1] # Add up the number of correct predictions. Indexed off the first point\n",
        "    batch_correct = (predicted == y_train).sum() # How many we got correct from this specific batch. True=1, False=0, sum those up.\n",
        "    training_correct += batch_correct # Keep track as we go along in training.\n",
        "\n",
        "    # Update the parameters\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Print out some results\n",
        "    if b % 600 == 0 :\n",
        "      print(f'Epoch: {i} Batch: {b} Loss: {loss.item()}')\n",
        "\n",
        "\n",
        "  train_losses.append(loss)\n",
        "  train_correct.append(training_correct)\n",
        "\n",
        "  # Test\n",
        "  with torch.no_grad(): # No gradient so the weights and the bias are not updated with test data\n",
        "    for b , (X_test, y_test) in enumerate(test_loader):\n",
        "      y_val = model(X_test)\n",
        "      predicted = torch.max(y_val.data, 1)[1] # Adding up correct predictions\n",
        "      testing_correct += (predicted == y_test).sum() # True=1, False=0, sum all\n",
        "\n",
        "  loss = criterion(y_val, y_test)\n",
        "  test_losses.append(loss)\n",
        "  test_correct.append(testing_correct)\n",
        "\n",
        "current_time = time.time()\n",
        "total = current_time - start_time\n",
        "print(f'Training time: {total/60} minutes!')\n",
        "total"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BoUW87PzO131",
        "outputId": "26314772-6d9d-4597-8999-81ea98f496ae"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 Batch: 600 Loss: 4.9471535021439195e-05\n",
            "Epoch: 0 Batch: 1200 Loss: 1.8047001503873616e-05\n",
            "Epoch: 0 Batch: 1800 Loss: 8.344646573732462e-08\n",
            "Epoch: 0 Batch: 2400 Loss: 0.003162816632539034\n",
            "Epoch: 0 Batch: 3000 Loss: 1.1622306374192704e-05\n",
            "Epoch: 0 Batch: 3600 Loss: 0.0001164354252978228\n",
            "Epoch: 0 Batch: 4200 Loss: 9.417489081897656e-07\n",
            "Epoch: 0 Batch: 4800 Loss: 0.00047675552195869386\n",
            "Epoch: 0 Batch: 5400 Loss: 0.0\n",
            "Epoch: 0 Batch: 6000 Loss: 1.609314722372801e-06\n",
            "Epoch: 1 Batch: 600 Loss: 2.777537929432583e-06\n",
            "Epoch: 1 Batch: 1200 Loss: 1.5139510196604533e-06\n",
            "Epoch: 1 Batch: 1800 Loss: 2.731903805397451e-05\n",
            "Epoch: 1 Batch: 2400 Loss: 1.889325176307466e-05\n",
            "Epoch: 1 Batch: 3000 Loss: 1.4351843674376141e-05\n",
            "Epoch: 1 Batch: 3600 Loss: 9.142941962636542e-06\n",
            "Epoch: 1 Batch: 4200 Loss: 8.943313878262416e-05\n",
            "Epoch: 1 Batch: 4800 Loss: 0.00012190106644993648\n",
            "Epoch: 1 Batch: 5400 Loss: 1.3207888514443766e-05\n",
            "Epoch: 1 Batch: 6000 Loss: 0.0\n",
            "Epoch: 2 Batch: 600 Loss: 2.1097897842992097e-05\n",
            "Epoch: 2 Batch: 1200 Loss: 0.0\n",
            "Epoch: 2 Batch: 1800 Loss: 8.022654583328404e-06\n",
            "Epoch: 2 Batch: 2400 Loss: 0.0\n",
            "Epoch: 2 Batch: 3000 Loss: 0.0\n",
            "Epoch: 2 Batch: 3600 Loss: 0.0013853703858330846\n",
            "Epoch: 2 Batch: 4200 Loss: 8.702245395397767e-07\n",
            "Epoch: 2 Batch: 4800 Loss: 0.0\n",
            "Epoch: 2 Batch: 5400 Loss: 5.555012648983393e-06\n",
            "Epoch: 2 Batch: 6000 Loss: 3.576274423267023e-07\n",
            "Epoch: 3 Batch: 600 Loss: 9.775114904186921e-07\n",
            "Epoch: 3 Batch: 1200 Loss: 1.1514954167068936e-05\n",
            "Epoch: 3 Batch: 1800 Loss: 7.748575399091351e-07\n",
            "Epoch: 3 Batch: 2400 Loss: 2.2887920749781188e-06\n",
            "Epoch: 3 Batch: 3000 Loss: 1.192092824453539e-08\n",
            "Epoch: 3 Batch: 3600 Loss: 0.0\n",
            "Epoch: 3 Batch: 4200 Loss: 0.002368538174778223\n",
            "Epoch: 3 Batch: 4800 Loss: 0.0001560908422106877\n",
            "Epoch: 3 Batch: 5400 Loss: 4.863749927608296e-05\n",
            "Epoch: 3 Batch: 6000 Loss: 1.5114685993466992e-05\n",
            "Epoch: 4 Batch: 600 Loss: 0.0\n",
            "Epoch: 4 Batch: 1200 Loss: 5.960462701182223e-08\n",
            "Epoch: 4 Batch: 1800 Loss: 2.384185648907078e-08\n",
            "Epoch: 4 Batch: 2400 Loss: 1.2159273410361493e-06\n",
            "Epoch: 4 Batch: 3000 Loss: 0.0002526980242691934\n",
            "Epoch: 4 Batch: 3600 Loss: 0.0036067436449229717\n",
            "Epoch: 4 Batch: 4200 Loss: 0.0\n",
            "Epoch: 4 Batch: 4800 Loss: 3.6161560274194926e-05\n",
            "Epoch: 4 Batch: 5400 Loss: 0.4160960614681244\n",
            "Epoch: 4 Batch: 6000 Loss: 4.497986446949653e-05\n",
            "Training time: 4.19429939587911 minutes!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "251.65796375274658"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "# Create Variables To Tracks Things\n",
        "epochs = 5\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "train_correct = []\n",
        "test_correct = []\n",
        "\n",
        "# For Loop of Epochs\n",
        "for i in range(epochs):\n",
        "  trn_corr = 0\n",
        "  tst_corr = 0\n",
        "\n",
        "\n",
        "  # Train\n",
        "  for b,(X_train, y_train) in enumerate(train_loader):\n",
        "    b+=1 # start our batches at 1\n",
        "    y_pred = model(X_train) # get predicted values from the training set. Not flattened 2D\n",
        "    loss = criterion(y_pred, y_train) # how off are we? Compare the predictions to correct answers in y_train\n",
        "\n",
        "    predicted = torch.max(y_pred.data, 1)[1] # add up the number of correct predictions. Indexed off the first point\n",
        "    batch_corr = (predicted == y_train).sum() # how many we got correct from this batch. True = 1, False=0, sum those up\n",
        "    trn_corr += batch_corr # keep track as we go along in training.\n",
        "\n",
        "    # Update our parameters\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "\n",
        "    # Print out some results\n",
        "    if b%600 == 0:\n",
        "      print(f'Epoch: {i}  Batch: {b}  Loss: {loss.item()}')\n",
        "\n",
        "  train_losses.append(loss)\n",
        "  train_correct.append(trn_corr)\n",
        "\n",
        "\n",
        "  # Test\n",
        "  with torch.no_grad(): #No gradient so we don't update our weights and biases with test data\n",
        "    for b,(X_test, y_test) in enumerate(test_loader):\n",
        "      y_val = model(X_test)\n",
        "      predicted = torch.max(y_val.data, 1)[1] # Adding up correct predictions\n",
        "      tst_corr += (predicted == y_test).sum() # T=1 F=0 and sum away\n",
        "\n",
        "\n",
        "  loss = criterion(y_val, y_test)\n",
        "  test_losses.append(loss)\n",
        "  test_correct.append(tst_corr)\n",
        "\n",
        "\n",
        "\n",
        "current_time = time.time()\n",
        "total = current_time - start_time\n",
        "print(f'Training Took: {total/60} minutes!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcGQGGnsPI1W",
        "outputId": "795be33a-24dd-46fe-909d-dfaf339f9a0c"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0  Batch: 600  Loss: 0.0027929155621677637\n",
            "Epoch: 0  Batch: 1200  Loss: 3.493723488645628e-05\n",
            "Epoch: 0  Batch: 1800  Loss: 0.0010003604693338275\n",
            "Epoch: 0  Batch: 2400  Loss: 0.1295616179704666\n",
            "Epoch: 0  Batch: 3000  Loss: 1.3505514289136045e-05\n",
            "Epoch: 0  Batch: 3600  Loss: 0.00021176428708713502\n",
            "Epoch: 0  Batch: 4200  Loss: 0.00011720164911821485\n",
            "Epoch: 0  Batch: 4800  Loss: 0.0009881147416308522\n",
            "Epoch: 0  Batch: 5400  Loss: 2.384185648907078e-08\n",
            "Epoch: 0  Batch: 6000  Loss: 0.0\n",
            "Epoch: 1  Batch: 600  Loss: 0.0008038681116886437\n",
            "Epoch: 1  Batch: 1200  Loss: 4.76837058727142e-08\n",
            "Epoch: 1  Batch: 1800  Loss: 3.4093500289600343e-06\n",
            "Epoch: 1  Batch: 2400  Loss: 3.4710730687947944e-05\n",
            "Epoch: 1  Batch: 3000  Loss: 0.0002807883720379323\n",
            "Epoch: 1  Batch: 3600  Loss: 9.417489081897656e-07\n",
            "Epoch: 1  Batch: 4200  Loss: 0.008015107363462448\n",
            "Epoch: 1  Batch: 4800  Loss: 0.00021272152662277222\n",
            "Epoch: 1  Batch: 5400  Loss: 7.617282335559139e-06\n",
            "Epoch: 1  Batch: 6000  Loss: 7.709871715633199e-05\n",
            "Epoch: 2  Batch: 600  Loss: 1.1241128959227353e-05\n",
            "Epoch: 2  Batch: 1200  Loss: 9.536717584524013e-07\n",
            "Epoch: 2  Batch: 1800  Loss: 0.0005367971025407314\n",
            "Epoch: 2  Batch: 2400  Loss: 4.148400421399856e-06\n",
            "Epoch: 2  Batch: 3000  Loss: 0.0\n",
            "Epoch: 2  Batch: 3600  Loss: 0.07778234779834747\n",
            "Epoch: 2  Batch: 4200  Loss: 1.001354917207209e-06\n",
            "Epoch: 2  Batch: 4800  Loss: 0.042573653161525726\n",
            "Epoch: 2  Batch: 5400  Loss: 0.0\n",
            "Epoch: 2  Batch: 6000  Loss: 0.00151331617962569\n",
            "Epoch: 3  Batch: 600  Loss: 1.4113868928689044e-05\n",
            "Epoch: 3  Batch: 1200  Loss: 2.2530307433044072e-06\n",
            "Epoch: 3  Batch: 1800  Loss: 2.384185471271394e-08\n",
            "Epoch: 3  Batch: 2400  Loss: 3.576272717964457e-07\n",
            "Epoch: 3  Batch: 3000  Loss: 2.384185648907078e-08\n",
            "Epoch: 3  Batch: 3600  Loss: 0.054267413914203644\n",
            "Epoch: 3  Batch: 4200  Loss: 0.680134654045105\n",
            "Epoch: 3  Batch: 4800  Loss: 0.0008131394279189408\n",
            "Epoch: 3  Batch: 5400  Loss: 1.3255626072350424e-05\n",
            "Epoch: 3  Batch: 6000  Loss: 1.0728830091011332e-07\n",
            "Epoch: 4  Batch: 600  Loss: 0.000250897224759683\n",
            "Epoch: 4  Batch: 1200  Loss: 0.0004779839946422726\n",
            "Epoch: 4  Batch: 1800  Loss: 0.0010529584251344204\n",
            "Epoch: 4  Batch: 2400  Loss: 0.001856612740084529\n",
            "Epoch: 4  Batch: 3000  Loss: 1.2707006135315169e-05\n",
            "Epoch: 4  Batch: 3600  Loss: 0.0\n",
            "Epoch: 4  Batch: 4200  Loss: 1.192092824453539e-08\n",
            "Epoch: 4  Batch: 4800  Loss: 3.576278118089249e-08\n",
            "Epoch: 4  Batch: 5400  Loss: 2.0265562739041343e-07\n",
            "Epoch: 4  Batch: 6000  Loss: 0.0012134775752201676\n",
            "Training Took: 4.140049517154694 minutes!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZSqn2niQgdd1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}