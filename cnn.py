# -*- coding: utf-8 -*-
"""CNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xAITneKZEYHdzNFK5PRqkrXTS0F7E0wA

# CNN

## Import MNIST Images - Deep Learning with PyTorch 14
"""

# Commented out IPython magic to ensure Python compatibility.
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader
from torchvision import datasets, transforms
from torchvision.utils import make_grid

import numpy as np
import pandas as pd
from sklearn.metrics import confusion_matrix
import matplotlib.pyplot as plt

# %matplotlib inline

# Convert MNIST Image Files into a Tensor of 4-Dimensions (# of images, Height, Width, Color Channel)
transform = transforms.ToTensor()

# Train Data
train_data = datasets.MNIST(root='/cnn_data', train=True, download=True, transform=transform)

# test Data
test_data = datasets.MNIST(root='/cnn_data', train=False, download=True, transform=transform)

train_data

test_data

pwd

ls

cd ../

ls -al

cd cnn_data

ls -l

cd /

ls -l

cd content/

ls -al

"""## Convolutional and Pooling Layers - Deep Learning with PyTorch 15

"""

# Create a small batch size for images...  let's say 10
train_loader = DataLoader(train_data, batch_size=10, shuffle=True)
test_loader = DataLoader(test_data, batch_size=10, shuffle=False)

# Define the CNN Model
# Decribe the convolutional layer and what it's doing (2 convolutional layers)
# This is an example
conv1 = nn.Conv2d(1, 6, 3, 1)
conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=3, stride=1)

# Grab 1 MNIST record/image
for i, (X_train, y_train) in enumerate(train_data):
  break

X_train

X_train.shape

x = X_train.view(1,1, 28, 28)

# Perform the first convolution
x = F.relu(conv1(x)) # Rectified Linear Unit for the activation function

x

# 1 is the single image, 6 is the filters asked for, 26x26
x.shape

# Pass through the pooling layer
x = F.max_pool2d(x, 2, 2) # Kernel of 2 and stride of 2

x.shape # 26 / 2 = 13

# Do the second convolutional layer
x = F.relu(conv2(x))

x.shape # Again, no padding was specified so 2 pixels were lost around the outside of the image

# Pooling layer
x = F.max_pool2d(x, 2, 2)

x.shape # 11 / 2 = 5.5 but it is rounded down because no data can invented to round up

(((28-2) / 2) -2) / 2