# -*- coding: utf-8 -*-
"""CNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xAITneKZEYHdzNFK5PRqkrXTS0F7E0wA

# CNN

## Import MNIST Images - Deep Learning with PyTorch 14
"""

# Commented out IPython magic to ensure Python compatibility.
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader
from torchvision import datasets, transforms
from torchvision.utils import make_grid

import numpy as np
import pandas as pd
from sklearn.metrics import confusion_matrix
import matplotlib.pyplot as plt

# %matplotlib inline

# Convert MNIST Image Files into a Tensor of 4-Dimensions (# of images, Height, Width, Color Channel)
transform = transforms.ToTensor()

# Train Data
train_data = datasets.MNIST(root='/cnn_data', train=True, download=True, transform=transform)

# test Data
test_data = datasets.MNIST(root='/cnn_data', train=False, download=True, transform=transform)

train_data

test_data

pwd

ls

cd ../

ls -al

cd cnn_data

ls -l

cd /

ls -l

cd content/

ls -al

"""## Convolutional and Pooling Layers - Deep Learning with PyTorch 15

"""

# Create a small batch size for images...  let's say 10
train_loader = DataLoader(train_data, batch_size=10, shuffle=True)
test_loader = DataLoader(test_data, batch_size=10, shuffle=False)

# Define the CNN Model
# Decribe the convolutional layer and what it's doing (2 convolutional layers)
# This is an example
conv1 = nn.Conv2d(1, 6, 3, 1)
conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=3, stride=1)

# Grab 1 MNIST record/image
for i, (X_train, y_train) in enumerate(train_data):
  break

X_train

X_train.shape

x = X_train.view(1,1, 28, 28)

# Perform the first convolution
x = F.relu(conv1(x)) # Rectified Linear Unit for the activation function

x

# 1 is the single image, 6 is the filters asked for, 26x26
x.shape

# Pass through the pooling layer
x = F.max_pool2d(x, 2, 2) # Kernel of 2 and stride of 2

x.shape # 26 / 2 = 13

# Do the second convolutional layer
x = F.relu(conv2(x))

x.shape # Again, no padding was specified so 2 pixels were lost around the outside of the image

# Pooling layer
x = F.max_pool2d(x, 2, 2)

x.shape # 11 / 2 = 5.5 but it is rounded down because no data can invented to round up

(((28-2) / 2) -2) / 2

"""## Convolutional Neural Network Model - Deep Learning with PyTorch 16

"""

# Model Class
class ConvolutionalNetwork(nn.Module):
  def __init__(self) -> None:
    super().__init__()
    self.conv1 = nn.Conv2d(1, 6, 3, 1)
    self.conv2 = nn.Conv2d(6, 16, 3, 1)

    # Fully Connected Layers
    self.fc1 = nn.Linear(5*5*16, 120)
    self.fc2 = nn.Linear(120, 84)
    self.fc3 = nn.Linear(84, 10)

  def forward(self, X):
    X = F.relu(self.conv1(X))
    X = F.max_pool2d(X, 2, 2) # 2x2 kernel and stride = 2
    # Second pass
    X = F.relu(self.conv2(X))
    X = F.max_pool2d(X, 2, 2) # 2x2 kernel and stride = 2

    # Re-View the data to flatten it out
    X = X.view(-1, 16*5*5) # Negative one so the batch size can be varied

    # Fully Connected Layers
    X = F.relu(self.fc1(X))
    X = F.relu(self.fc2(X))
    X = self.fc3(X)

    return F.log_softmax(X, dim=1)

# Create an Instance of the Model
torch.manual_seed(41)
model = ConvolutionalNetwork()
model

# Loss Function Optimizer
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.001) # The smaller the learning rate, the longer it's going to take to train